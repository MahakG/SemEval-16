#############
# Tokenizer #
#############

#imports
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.linear_model import SGDClassifier
import numpy

#Retrieve training data

f = open('../data/train.txt','r');
tweets = [];
target = [];
for line in f :
	if line != '' and line != '\n':
		listLine = line.strip().split('\t');
		tweets.append(listLine[0]);
		target.append(listLine[1]);

#Retrieve testing data
f_test = open('../data/tweets_test.txt','r');
test_data = [];
test_target = [];
for line in f_test :
	if line != '' and line != '\n':
		listLine = line.strip().split('\t');
		test_data.append(listLine[0]);
		test_target.append(listLine[1]);

#Vectorization of tweets into a ocurrence matrix.
cv = CountVectorizer();
X_train_count = cv.fit_transform(tweets);
print(X_train_count.shape);


#Transform ocurrences into frequencies.

tfidf = TfidfTransformer();
X_train_tfidf = tfidf.fit_transform(X_train_count);
print(X_train_tfidf.shape);



#Classifier

svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42);

svm.fit(X_train_tfidf, target);

X_test_count = cv.transform(test_data);
print(X_test_count.shape);
X_test_tfidf = tfidf.transform(X_test_count);
print(X_test_tfidf.shape);
predicted = svm.predict(X_test_tfidf);

#Print results
for doc, category in zip(test_data, predicted) :
	print(doc+"\t"+category);


#Evaluation
print(numpy.mean(predicted == test_target));
